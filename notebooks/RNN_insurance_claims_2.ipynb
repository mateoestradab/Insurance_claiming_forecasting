{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "improving-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,  LSTM\n",
    "from tensorflow.keras import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "plastic-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('../raw_data/daily_data_clean.xlsx', engine='openpyxl').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "romance-collar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_issue</th>\n",
       "      <th>total_amount_claims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-02</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-03</td>\n",
       "      <td>16169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>28529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>64135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_issue  total_amount_claims\n",
       "0 2018-09-01                  168\n",
       "1 2018-09-02                  346\n",
       "2 2018-09-03                16169\n",
       "3 2018-09-04                28529\n",
       "4 2018-09-05                64135"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "introductory-minister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "920"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_data = len(data)\n",
    "len_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(number):\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(number):\n",
    "        x_i, y_i = create_individual_sequence(10)\n",
    "        X.append(x_i)\n",
    "        y.append(y_i)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "            \n",
    "def create_individual_sequence(length):\n",
    "    amount_claims = []\n",
    "    \n",
    "    # Amount Claims\n",
    "    nb_iter = np.random.beta(.15, 4)*300\n",
    "    for i in range(length):\n",
    "        if not np.random.randint(2): # Change 1 out of 2 possibilities\n",
    "            R_1 = np.random.beta(0.5, 8)*3\n",
    "            nb_iter = nb_iter + max(-2, R_1*company_sizes[i] + np.random.randint(-2, 2))\n",
    "            nb_iter = max(0, nb_iter)\n",
    "            nb_iter = int(min(company_sizes[i]-1, nb_iter))\n",
    "        nb_persons.append(nb_iter)\n",
    "        \n",
    "    \n",
    "    # Salary\n",
    "    salary_iter = max(800, int(np.random.normal(1200, 300)+ 0.05*company_sizes[0] +  np.random.normal(40, 400)))\n",
    "    salaries.append(salary_iter)\n",
    "    for i in range(1, length + 1):\n",
    "        R_1 = np.random.normal(100, 50)\n",
    "        change_person = nb_persons[i-1] - nb_persons[i-2]\n",
    "        change_company = max(0, company_sizes[i-1] - company_sizes[i-2])\n",
    "        salary_iter = salary_iter + 0.05*change_company + change_person*R_1 + np.random.normal(100, 50)\n",
    "        salary_iter = max(int(salary_iter), 500)\n",
    "        \n",
    "        salaries.append(salary_iter)\n",
    "\n",
    "    y = salaries[-1]/1000\n",
    "    salaries = [_/1000 for _ in salaries[:-1]]\n",
    "    \n",
    "    return np.array([salaries, nb_persons, company_sizes]).T, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-house",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-cache",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-concentration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-testing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-kitchen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-jamaica",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-genre",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['total_amount_claims']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert feature to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use shifted versions of the column Y as independent variables, that is to say use 3 delays of Y\n",
    "# as inputs to predict the output of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = y[0:len_data-3,:]\n",
    "X2 = y[1:len_data-2,:]\n",
    "X3 = y[2:len_data-1,:]\n",
    "y = y[3:len_data,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X1,X2,X3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X shape is {X.shape}')\n",
    "print(f'Y shape is {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we standardize our data both our variable x and our variable y between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM needs 3 dimensional input so we have to reshape the X input into 3 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "scaler.fit(y)\n",
    "y = scaler.transform(y)\n",
    "\n",
    "X= np.reshape(X, (X.shape[0],1,X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and test sets for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X train size:{X_train.shape}')\n",
    "print(f'X test size:{X_test.shape}')\n",
    "print(f'y train size:{y_train.shape}')\n",
    "print(f'y test size:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units= 10,activation = 'tanh',input_shape = (1,3),recurrent_activation= 'hard_sigmoid')) #DUDA: APLICAR RETURN SEQUENCES O NO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use mean absolute error to assess our model and then we fit our model to the training set and launch the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'mean_squared_error',optimizer = 'rmsprop', metrics=['mae'])\n",
    "model.fit(X_train,y_train,epochs=100,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Model Mean Absolute Error {model_mae[1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s now have a visualization comparing the prediction versus the test set to see how our model performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(y_test,label = 'Test')\n",
    "plt.plot(Predict, label = 'Prediction')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s now add time indexes and scale back to the original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = scaler.inverse_transform(y_train)\n",
    "# y_train = pd.DataFrame(y_train)\n",
    "# y_train.index = pd.to_datetime(data.iloc[3:736,0])\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = scaler.inverse_transform(y_test)\n",
    "# y_test = pd.DataFrame(y_test)\n",
    "# y_test.index = pd.to_datetime(data.iloc[736:,0])\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict = model.predict(X_test)\n",
    "# Predict = scaler.inverse_transform(Predict)\n",
    "# Predict = pd.DataFrame(Predict)\n",
    "# Predict.index=pd.to_datetime(data.iloc[736:,0])\n",
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,10))\n",
    "# plt.plot(y_test)\n",
    "# plt.plot(Predict)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame to compare Y in train with the prediction of model \n",
    "\n",
    "test_vs_pred_df= test.merge(forecast_test, on='ds', how='left')\n",
    "merged_df\n",
    "test_vs_pred_df = pd.DataFrame(merged_df[['ds', 'y', 'yhat']]).copy()\n",
    "test_vs_pred_df['absolute_error'] = abs(test_vs_pred_df['y'] - test_vs_pred_df['yhat'])\n",
    "test_vs_pred_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
