{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Day 4 - Your First RNN\n",
    "\n",
    "### Exercise objectives:\n",
    "\n",
    "- Better understand temporal data\n",
    "- Build your first Recurrent Neural Network\n",
    "\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "You will see along the different exercises that temporal data can be of very different type - and thus of different complexity. For that reason, let's start with simple sequences of observations.\n",
    "\n",
    "\n",
    "# The data\n",
    "\n",
    "\n",
    "The data describes the evolution of the employment status of a person, year after year: each sequence corresponds to 6 consecutive years, where each year describes a job (let's say for the sake of simplicity that it corresponds to the job on the 1st of January). And each job is described by\n",
    "- the salary,\n",
    "- the number of persons under one's responsability,\n",
    "- the size of the company. \n",
    "\n",
    "For instance, if at a given year, you earn 2500 ($, €, ¥, ...), you have 4 persons under your responsibility and the company has 200 employes, then it corresponds to the vector (2.5, 4, 200) - note here that the salary is devided by 1000 to have something normalized. And you have this observation for 10 consecutive years.\n",
    "\n",
    "So, from this 25000 sequences, each of 10 consecutive observations, the goal is to predict the salary on the 11th year based on the past observations. \n",
    "\n",
    "❓ **Question** ❓ Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the data here.\n",
    "\n",
    "❓ **Question** ❓ Take some sequences and plot the evolution of their salaries, of the persons under their responsibility and of the company sizes. You might see some correlation between the three variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "### Answer ###\n",
    "##############\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "random_selection = np.random.randint(0, X.shape[0], 4)\n",
    "\n",
    "plt.title('Salary')\n",
    "for r in random_selection:\n",
    "    plt.plot(X[r, :, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.title('Person under responsibility')\n",
    "for r in random_selection:\n",
    "    plt.plot(X[r, :, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.title('Company sizes')\n",
    "for r in random_selection:\n",
    "    plt.plot(X[r, :, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Plot the distribution of all the salaries, persons under one's responsibility, and company sizes to get a better understanding of the variability of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "### Answer ###\n",
    "##############\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.title(\"Seen salaries\")\n",
    "plt.hist(X[:, -1, 0].flatten())\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"# of persons under responsibility\")\n",
    "plt.hist(X[:, :, 1].flatten())\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Company sizes\")\n",
    "plt.hist(X[:, :, 2].flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓  Split your dataset between a train and test set (20/80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "Now, you will create your first Recurrent Neural Network.\n",
    "\n",
    "❓ **Question** ❓ Write a model that has: \n",
    "- a `SimpleRNN` layer with 20 `units` - don't forget to choose the `tanh` activation function\n",
    "- a Dense layer with 10 neurons\n",
    "- a last Dense layer specific to your task (predict a salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "### Answer ###\n",
    "##############\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import  Dense, SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=20, activation='tanh'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Compile your model. Remember to first use the `rmsprop` optimizer (instead of Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "### Answer ###\n",
    "##############\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer='rmsprop', \n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Run your model on your data. Use a validation split of 20% and an early stopping criterion (patience=5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "### Answer ###\n",
    "##############\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=5)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=100, \n",
    "          batch_size=32, \n",
    "          validation_split=0.2,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Evaluate your model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "### Answer ###\n",
    "##############\n",
    "\n",
    "model_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Model Mean Absolute Error {model_mae[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "\n",
    "\n",
    "### Standard problems\n",
    "\n",
    "As for any model, you should quickly get an idea of the performance of your model. For instance, in case of a 2-class equally-balanced classification, the worst accuracy is of 50%. If the classe is unbalanced, your worst classification consists in always predicting the most present class. Similar ideas go for multiclass classification.\n",
    "\n",
    "In the case of a regression model, a baseline prediction for `y_test` could be to predict the average of `y_train`.\n",
    "\n",
    "### Temporal problems\n",
    "\n",
    "With temporal data, it often happens that you try to predict a value that you have already seen in the past: here, the salary. In that case, a baseline model could be to predict a value based on these past occurencies. For instance, here, you could predict that the 11-th salary is equal to the 10-th salary.\n",
    "\n",
    "❓ **Question** ❓ Compute the Mean Absolute Error of a model that would predict that the salary remains constant between the 10-th and 11-th year and compare it to your RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "### Answer ###\n",
    "##############\n",
    "\n",
    "def constant_prediction(X, y):\n",
    "    ae = []\n",
    "    for xx, yy in zip(X, y):\n",
    "        last_salary = xx[-1][0]\n",
    "        ae.append(yy - last_salary)\n",
    "        \n",
    "    return ae\n",
    "\n",
    "ae = constant_prediction(X, y)\n",
    "\n",
    "print(f'Constant Mean Absolute Error {np.mean(np.abs(ae)):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have probably seen that your prediction is a little bit better than the baseline model\n",
    "\n",
    "# A bit more complex model\n",
    "\n",
    "❓ **Question** ❓ Write the exact same model, but with a `LSTM` instead of a `SimpleRNN` and evaluate your performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "### Answer ###\n",
    "##############\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(LSTM(units=20, activation='tanh'))\n",
    "model_LSTM.add(Dense(10, activation='relu'))\n",
    "model_LSTM.add(Dense(1, activation='linear'))\n",
    "\n",
    "model_LSTM = compile_model(model_LSTM)\n",
    "\n",
    "es = EarlyStopping(patience=5)\n",
    "\n",
    "model_LSTM.fit(X_train, y_train,\n",
    "          epochs=100, \n",
    "          batch_size=32, \n",
    "          validation_split=0.2,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well done!\n",
    "\n",
    "## You now know how to run RNN on sequence data!\n",
    "\n",
    "Note: The sequences you worked with are totally fake. In case you need to train and reproduce similar data, you can find bellow the functions that have been used to simulate this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(number):\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(number):\n",
    "        x_i, y_i = create_individual_sequence(10)\n",
    "        X.append(x_i)\n",
    "        y.append(y_i)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "            \n",
    "def create_individual_sequence(length):\n",
    "    company_sizes = []\n",
    "    nb_persons = []\n",
    "    salaries = []\n",
    "    \n",
    "    \n",
    "    # Education level\n",
    "    educ_level = [max(0, int(np.random.normal(10, 2)))]*length\n",
    "    \n",
    "    # Company size\n",
    "    current_size = int(1 + np.random.beta(.4, 4)*500)\n",
    "    for i in range(length):\n",
    "        if not np.random.randint(4): # Change 1 out of 3 possibilities \n",
    "            current_size = int(max(1, np.random.normal(current_size, 50)))\n",
    "        company_sizes.append(current_size)\n",
    "    \n",
    "    # Number of persons\n",
    "    nb_iter = np.random.beta(.15, 4)*300\n",
    "    for i in range(length):\n",
    "        if not np.random.randint(2): # Change 1 out of 2 possibilities\n",
    "            R_1 = np.random.beta(0.5, 8)*3\n",
    "            nb_iter = nb_iter + max(-2, R_1*company_sizes[i] + np.random.randint(-2, 2))\n",
    "            nb_iter = max(0, nb_iter)\n",
    "            nb_iter = int(min(company_sizes[i]-1, nb_iter))\n",
    "        nb_persons.append(nb_iter)\n",
    "        \n",
    "    \n",
    "    # Salary\n",
    "    salary_iter = max(800, int(np.random.normal(1200, 300)+ 0.05*company_sizes[0] +  np.random.normal(40, 400)))\n",
    "    salaries.append(salary_iter)\n",
    "    for i in range(1, length + 1):\n",
    "        R_1 = np.random.normal(100, 50)\n",
    "        change_person = nb_persons[i-1] - nb_persons[i-2]\n",
    "        change_company = max(0, company_sizes[i-1] - company_sizes[i-2])\n",
    "        salary_iter = salary_iter + 0.05*change_company + change_person*R_1 + np.random.normal(100, 50)\n",
    "        salary_iter = max(int(salary_iter), 500)\n",
    "        \n",
    "        salaries.append(salary_iter)\n",
    "\n",
    "    y = salaries[-1]/1000\n",
    "    salaries = [_/1000 for _ in salaries[:-1]]\n",
    "    \n",
    "    return np.array([salaries, nb_persons, company_sizes]).T, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = create_sequences(25000)\n",
    "\n",
    "#np.save('X', X.astype(np.float32))\n",
    "#np.save('y', y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
